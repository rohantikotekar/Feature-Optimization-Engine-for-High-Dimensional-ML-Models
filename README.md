# Feature Optimization Engine for High Dimensional ML Models

## Problem Statement

A Machine Learning model is as good as its data. During pre-processing, ML Engineers face the problem of feature selection. Dropping irrelevant features is a key step for the model to perform well. However, this process cannot yield optimal results if it is done purely based on Human judgement. 

## Solution

My method automates the process of finding the best possible features to get a good accuracy. It uses forward propagation and backward elimination algorithms to find the most optimized subset of features. These features are then given to the ML model for training. 

## Resume Description 

1. Architected a scalable, dataset-agnostic Nearest Neighbor classification framework simulating production-grade pre-processing workflows.
2. Designed and implemented forward and backward wrapper-based feature selection modules, enabling dynamic subset evaluation and delivering up to 30% lift in classification accuracy on noisy datasets.
3. Reduced feature footprint by 70%+ across multiple scenarios, significantly improving model inference latency and stability while maintaining cross-validated generalization performance.
4. Delivered a modular, test-traceable ML evaluation pipeline with automated cross-validation, performance logging, and iterative feature relevance tracking â€” enabling explainability and reproducibility.
   
## Output 

<img width="1061" alt="image" src="https://github.com/user-attachments/assets/786368c4-663e-44a6-851c-b53810b334d5" />
